{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T01:06:25.544768Z",
     "start_time": "2019-06-21T01:06:25.534782Z"
    }
   },
   "source": [
    "# 1. GRADIENT DESCENT\n",
    "<a id='top'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents**\n",
    "\n",
    "<br> 1.1 [Gradient Descent Demistified](#GradientDescent)\n",
    "<br> 1.2 [Gradient Descent in Machine Learning](#GDImportance)\n",
    "<br> 1.3 [Initializing the session and setting directories](#StartingSession)\n",
    "<br> 1.4 [The Six-Hump Camel Function](#TheSixHumpCamelFunction)\n",
    "<br> 1.5 [Initializing the Gradient Descent Exercise](#InitializeGD)\n",
    "<br> 1.6 [Plain Vanilla Gradient Descent](#PlainVanillaGD)\n",
    "<br> 1.7 [Momentum Gradient Descent](#MomentumGD)\n",
    "<br> 1.8 [Nestrov's Accelerated Gradient Descent](#NestAccGD)\n",
    "<br> 1.9 [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='GradientDescent'></a>\n",
    "## 1.1 Gradient Descent Demistified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - In this section we will discuss Plain Vanilla Gradient Descent and two of its variants:\n",
    "     - Momentum Gradient Descent\n",
    "     - Nestrov's Accelerated Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig'></a> \n",
    "<br> [Go to Plain Vanilla](#pv)\n",
    "<br> [Go to Momentum GD](#mgd)\n",
    "<br> [Go to Nestrov's Accelerated GD](#nag)"
   ]
  },
  {
   "attachments": {
    "hill.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hill.png](attachment:hill.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - To explain the three types of gradient descent, we will use an analogy of a boy with two balls (a deflated ball and an inflated ball) going down a hill. \n",
    " - In this case, the hill represents our cost function, the point D is the lowest point(global minimum) which is our goal.\n",
    " - The other valleys(B and F) are also valleys/low points(local minima) but they are not the lowest point(global minimum)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pv'></a>\n",
    "### 1.1.1 Plain Vanilla Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Plain Vanilla gradient descent behaves like the deflated ball.\n",
    " - Initially, it will be going down the hill at a speed equal to the inflated ball.\n",
    " - As it approaches point B (a local minimum), it loses momentum and slows down faster than the inflated ball.\n",
    " - Since it has reached a local minimum point at point B, it will settle there instead of going past B and C to land at point D (the global minimum).[(Refer to the image)](#fig)\n",
    " - This illustrates the main challenges of plain vanilla, since although it settles at a minimum in most cases, it fails to go past a local minimum or even a level plain (referred to as saddle point).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mgd'></a>\n",
    "### 1.1.2 Momentum Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Momentum gradient descent is like the inflated ball.\n",
    "* Initially it will go down the hill at almost the same rate as the deflated ball.\n",
    "* However, it will not lose momentum as fast as the deflated ball.\n",
    "* It will therefore accelerate past point B.\n",
    "* Its destination however depends on its speed:\n",
    "    1.\tIf it is not rolling at a fast speed, it will get close to point C then start heading back towards B. It will keep going to and from both ends of B before finally settling on B\n",
    "    2.\tIf it is rolling at a fast speed, it will go past point C and maybe oscillate around point D before settling at there or accelerate and go past point D and E.[(Refer to the image)](#fig)\n",
    "* The main advantage of momentum over plain-vanilla is that in most cases that it settles at a minimum, it will settle at the global minimum (it will go past the other local minimums.\n",
    "* Also momentum gradient descent will get to the minimum point faster than plain-vanilla gradient descent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='nag'></a>\n",
    "### 1.1.3 Nestrovs Accelerated Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nestrovs accelerated gradient descent is like the young boy.\n",
    "* Unlike the balls, the young boy can see ahead and knows if there is another descent past the current local minimum B (beyond point C).\n",
    "* He will accelerate down the hill from point A to B and tries to keep the momentum to boost him beyond point C onto the steeper descent.\n",
    "* However, whether he stops at point D or not depends on the speed he descends with from point C and if he perceives there to be another minimum beyond E.[(Refer to the image)](#fig)\n",
    "* The main advantage of Nestrovs Accelerated Gradient Descent is that in most cases, it knows when it is approaching a valley and can slow down so as to settle at the valley unlike momentum.\n",
    "* It therefore settles at a minimum in more cases than momentum.\n",
    "* It however suffers from the fact that it might settle at other minimums beyond the global minimum at D if it perceives the next valley(F) beyond E.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='GDImportance'></a>\n",
    "## 1.2 Gradient Descent in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent is an algorithm that is used in optimizing a function. \n",
    "1.\tIn machine learning, gradient descent is used to find the function/model that best maps a given set of inputs to the output.\n",
    " - For example, in a given company:\n",
    "         - You are given a dataset of inputs (such as labour hours, machine hours and quantity of raw material consumed) and output (quantity manufactured goods).\n",
    "         - The data has been collected daily over a given time period. \n",
    "         - The company wants to develop a model(function) to be used to predict the output given a set inputs. \n",
    "         - This model will then be used by the company to gauge the effect of changing any input on the overall output in future.\n",
    "         - Gradient descent can thus be applied to get the correct weights that will give the best function. \n",
    "         - Initially the model will be given random weights for each of the inputs (say uniform weights)\n",
    "         - The model will then be used to predict the output for the dataset of inputs. The differences between the predicted outputs and the actual outputs (the error) dictate how the weights can be adjusted.\n",
    "         - If the model has over(under) predicted, the weights are reduced(increased) and the process continues till the best weights are determined.\n",
    "2.\tIt is also used in network analysis which is very key in implementing artificial intelligence systems such as the development of robotics, driverless cars, etc.\n",
    " - The goal is to train the model to ensure that it is able to decipher and communicate the right message in most reasonable situations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='StartingSession'></a>\n",
    "## 1.3 Initializing the session and setting directories\n",
    "[Go to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:17:59.587178Z",
     "start_time": "2019-07-12T00:17:59.582185Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Setting the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:17:59.707886Z",
     "start_time": "2019-07-12T00:17:59.602358Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/drive')\n",
    "#os.chdir('/drive/My Drive/AML/Projects/Question_1/')\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:18:11.852795Z",
     "start_time": "2019-07-12T00:17:59.707886Z"
    }
   },
   "outputs": [],
   "source": [
    "# Computational modules\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import pandas as pd\n",
    "import gradient_descent #The module we created for gradient descent\n",
    "from collections import Counter\n",
    "\n",
    "# Plotting modules\n",
    "import matplotlib\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML, Image\n",
    "\n",
    "from ipywidgets import interact, interactive, interact_manual, FloatSlider, IntSlider\n",
    "\n",
    "font = {'size': 18}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TheSixHumpCamelFunction'></a>\n",
    "## 1.4 The Six-Hump Camel Function\n",
    "[Go to top](#top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The six-hump camel function is an optimization test problem\n",
    " - The function is evaluated within x={-3,3} and y={-2,2}\n",
    " - The function has six local minima of which two are the global minima.\n",
    " - The global minima of the function lies at f(x,y)=-1.0316 at (x,y)=(0.0898,-0.7126) and (-0.0898,0.7126)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T20:17:53.884642Z",
     "start_time": "2019-06-28T20:17:53.880790Z"
    }
   },
   "source": [
    "### 1.4.1 Initializing the Six-Himp Camel Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Loss function is:    $f(x,y)=(4-2.1x^2+x^4/3)x^2+xy+(-4+4y^2)y^2$\n",
    " - Partial Derivative with respect to x is:    $df(x,y)=8x - 8.4x^3+2x^5+y$\n",
    " - Partial Derivative with respect to y is:    $df(x,y)=x-8y+16y^3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:18:11.861768Z",
     "start_time": "2019-07-12T00:18:11.856769Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_loss(x, y):\n",
    "    return (4 - 2.1*(x**2) + (x**4)/3)*(x**2) + x*y + (-4 + 4*(y**2))*(y**2)\n",
    "    \n",
    "def fn_grad1(x, y):\n",
    "    return 8*x - 8.4*(x**3) + 2*(x**5) + y\n",
    "\n",
    "def fn_grad2(x, y):\n",
    "    return x - 8*y + 16*(y**3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Visualizing the 6-Hump Camel Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2.1 Plot of the function within its recommended input domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:18:13.979743Z",
     "start_time": "2019-07-12T00:18:11.865768Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 9))\n",
    "\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "#ax1 = plt.axes(projection='3d')\n",
    "x = np.linspace(-3, 3, 30)\n",
    "y = np.linspace(-2, 2, 30)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = fn_loss(X, Y)\n",
    "\n",
    "font = {'size': 4}\n",
    "ax1.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax1.set_title('Six hump Camel function');\n",
    "ax1.set_xlabel('x', labelpad=15)\n",
    "ax1.set_ylabel('y', labelpad=15)\n",
    "ax1.set_zlabel('Loss Function', labelpad=15)\n",
    "ax1.set_yticks([-2,-1,0,1,2]);\n",
    "\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "#ax2 = plt.axes(projection='3d')\n",
    "ax2.set_ylim3d(-1, 1)\n",
    "ax2.set_xlim3d(-2, 2)\n",
    "x = np.linspace(-2, 2, 30)\n",
    "y = np.linspace(-1, 1, 30)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = fn_loss(X, Y)\n",
    "\n",
    "\n",
    "ax2.yaxis.set_tick_params(labelsize=20)\n",
    "\n",
    "\n",
    "ax2.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax2.set_title('Six hump Camel function-Close up');\n",
    "ax2.set_xlabel('x', labelpad=15)\n",
    "ax2.set_ylabel('y', labelpad=15)\n",
    "ax2.set_zlabel('Loss Function', labelpad=15)\n",
    "ax2.set_xticks([-2,-1,0,1,2])\n",
    "ax2.set_yticks([-1,-0.5,0,0.5,1]);\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Save image for report\n",
    "fig.savefig('6_hump_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2.2 Interactive Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:18:13.999685Z",
     "start_time": "2019-07-12T00:18:13.979743Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_view(xmin,xmax,ymin,ymax):\n",
    "  fig = plt.figure(figsize=(10,9))\n",
    "  ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "  # Make data.\n",
    "  X = np.arange(xmin, xmax, 0.0025)\n",
    "  #xlen = len(X)\n",
    "  Y = np.arange(ymin,ymax, 0.0025)\n",
    "  #ylen = len(Y)\n",
    "  X, Y = np.meshgrid(X, Y)\n",
    "  Z = fn_loss(X,Y)\n",
    "  surf = ax.plot_surface(X, Y, Z, linewidth=0,cmap='viridis')\n",
    "  ax.set_xlabel('x', labelpad=15)\n",
    "  ax.set_ylabel('y', labelpad=15)\n",
    "  ax.set_zlabel('Loss Function', labelpad=15)             \n",
    "  ax.set_title(label = 'Interactive six hump plot', loc='left')\n",
    "  ax.set_xticks(np.arange(xmin, xmax, step=1))\n",
    "  ax.set_yticks(np.arange(xmin, xmax, step=1));\n",
    "  plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:18:16.715690Z",
     "start_time": "2019-07-12T00:18:13.999685Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interactive_six_hump_cont  = interactive(plot_view, xmin=FloatSlider(description='Minimum x', min=-3, max=3, step=0.1,readout_format = '.1f',value = -3),\n",
    "                                         xmax=FloatSlider(description='Maximum x', min=-3, max=3, step=0.1,readout_format = '.1f',value = 3),\n",
    "                                         ymin=FloatSlider(description='Minimum y',min=-2, max=2, step=0.1,readout_format = '.1f',value = -2),\n",
    "                                         ymax =FloatSlider(description='Maximum y',min=-2, max=2, step=0.1,readout_format = '.1f',value = 2))\n",
    "output = interactive_six_hump_cont.children[4]\n",
    "output.layout.height = '550px'\n",
    "interactive_six_hump_cont  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T20:12:11.910190Z",
     "start_time": "2019-06-28T20:12:11.903308Z"
    }
   },
   "source": [
    "<a id='InitializeGD'></a>\n",
    "## 1.5 Initializing the Gradient Descent Exercise\n",
    "[Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 Calling the Gradient Descent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:18:16.728687Z",
     "start_time": "2019-07-12T00:18:16.720690Z"
    }
   },
   "outputs": [],
   "source": [
    "solver = gradient_descent.GradientDescent(fn_loss = fn_loss, fn_grad1 = fn_grad1, fn_grad2 = fn_grad2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 Determinining the maximum step size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Our choice starting point of (x, y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:18:16.947689Z",
     "start_time": "2019-07-12T00:18:16.731694Z"
    }
   },
   "outputs": [],
   "source": [
    "x_init = 3\n",
    "y_init = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:18:17.114487Z",
     "start_time": "2019-07-12T00:18:16.948691Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Step size therefore should limit the movement within the recommended bounds of x and y:\n",
    "step_size1 = np.abs((x_init*2)/(fn_grad1(x_init,y_init)))\n",
    "step_size2 = np.abs((y_init*2)/(fn_grad2(x_init,y_init)))\n",
    "step_size = np.minimum(step_size1,step_size2)\n",
    "\n",
    "print('The maximum step size is: {}'.format(np.round(step_size,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T15:27:14.881654Z",
     "start_time": "2019-07-05T15:27:14.870733Z"
    }
   },
   "source": [
    "- For a step-size above 0.021, the fuction will go beyond its recommended input domain of (-3,3) and (-2,2)\n",
    "- To make sure it converges, we limit the step size to the maximimum above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-28T20:12:11.910190Z",
     "start_time": "2019-06-28T20:12:11.903308Z"
    }
   },
   "source": [
    "<a id='PlainVanillaGD'></a>\n",
    "## 1.6 Plain Vanilla Gradient Descent\n",
    "[Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.1 Interactive Demonstartion of Plain Vanilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is an interactive module for demonstrating gradient descent**\n",
    " - **To run this, you need to select the initial value of x and y**\n",
    " - **After selecting the initial values, you click \"Run Interact\" button to visualize the gradient descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:18:17.460452Z",
     "start_time": "2019-07-12T00:18:17.114487Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interactive_plain_vanilla_gd_manual = interact_manual(solver.find_min, x_init=FloatSlider(description='Initial x', min=-3, max=3, step=0.1,readout_format = '.1f',value = 3),\n",
    "                                                 y_init=FloatSlider(description='Initial y', min=-2, max=2, step=0.1,readout_format = '.1f',value = 2),\n",
    "                                                 max_iter=IntSlider( min=0, max=2000, step=1,value = 2000),\n",
    "                                                 eta=FloatSlider(description='Step size',min=0.001, max=0.02, step=0.001,readout_format = '.3f',value = 0.001),\n",
    "                                                 tol =FloatSlider(description='Tolerance',min=0, max= 0.001, step=1e-5,readout_format = '.4f',value =  1e-5))\n",
    "\n",
    "interactive_plain_vanilla_gd_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T02:22:19.197048Z",
     "start_time": "2019-07-10T02:22:16.340114Z"
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.2 Animated Path of the loss function for a step size of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:18:17.519526Z",
     "start_time": "2019-07-12T00:18:17.460452Z"
    }
   },
   "outputs": [],
   "source": [
    "solver.plain_vanilla(x_init, y_init, max_iter = 2000, eta = 0.001, tol = 0.1)\n",
    "x_data = solver.x_path\n",
    "y_data = solver.y_path\n",
    "z_data = solver.loss_path\n",
    "\n",
    "nfr = solver.num_iters+1 # we set number of frames\n",
    "fps = 10 # Frame per sec\n",
    "xs = []\n",
    "ys = []\n",
    "zs = []\n",
    "ss = np.arange(0,nfr,1)\n",
    "for s in ss:\n",
    "    xs.append(x_data[s])\n",
    "    ys.append(y_data[s])\n",
    "    zs.append(z_data[s])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:06.601610Z",
     "start_time": "2019-07-12T00:18:17.519526Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.style.use('dark_background')\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "xc = np.linspace(np.min(x_data),np.max(x_data),50)\n",
    "yc = np.linspace(np.min(y_data),np.max(y_data),50)\n",
    "X, Y = np.meshgrid(xc, yc)\n",
    "Z = fn_loss(X, Y)\n",
    "\n",
    "#Surface plot\n",
    "ax.plot_surface(X, Y, Z, rstride=1, cstride=1, color='grey')\n",
    "line, = ax.plot([], [], [], 'r-', label = 'Gradient descent', lw = 1.5)\n",
    "sct, = ax.plot([], [], [], marker = 'o', markersize=3, color = 'red')\n",
    "display_value = ax.text(1.6, 2.0, 100, '')\n",
    "\n",
    "def update(ifrm, xa, ya, za):\n",
    "    sct.set_data(xa[ifrm], ya[ifrm])\n",
    "    sct.set_3d_properties(za[ifrm])\n",
    "    line.set_data(xa[:ifrm], ya[:ifrm])\n",
    "    line.set_3d_properties(za[:ifrm])\n",
    "    display_value.set_text('Min = ' + str(np.round(za[ifrm],4)))\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('loss function')\n",
    "ax.set_title('Loss path')\n",
    "ax.set_xlim(np.min(x_data),np.max(x_data))\n",
    "ax.set_ylim(np.min(y_data),np.max(y_data))\n",
    "ax.set_zlim(np.min(z_data),np.max(z_data))\n",
    "ani = animation.FuncAnimation(fig, update, nfr, fargs=(xs,ys,zs), interval=200/fps,repeat = True)\n",
    "\n",
    "# save the animation as mp4 video file \n",
    "#ani.save('loss_path.gif',writer='pillow')\n",
    "\n",
    "#Visualize the animation\n",
    "HTML(ani.to_jshtml())\n",
    "\n",
    "#ax.plot(x_data, y_data, z_data, marker = 'o', color = 'r', alpha = .4, label = 'Gradient descent')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to Note**\n",
    "- **The animation can be found in the working directory and is computed at a high tolerance of 0.1**\n",
    "- **For our analysis, we will use a tolerance of 0.00001(1e-5)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.3 Select Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='PlainVanillaGD_0.001'></a>\n",
    "#### 1.6.3.1 Path of the loss function for a step size of 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to Momentum at step size 0.001](#MomentumGD_0.001)                         \n",
    "[Go to Nestrov's at step size 0.001](#NestrovsAGD_0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For our comparison of the three types of gradient descent, we will use a step size of 0.01**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:06.628602Z",
     "start_time": "2019-07-12T00:20:06.605611Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "solver.plain_vanilla(x_init, y_init, max_iter = 2000, eta = 0.001, tol = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:07.485485Z",
     "start_time": "2019-07-12T00:20:06.630599Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vizualize loss path\n",
    "x1 = solver.x_path\n",
    "y1 = solver.y_path\n",
    "z1 = solver.loss_path\n",
    "loss_min = np.round(solver.loss_fn_min,4)\n",
    "iterations = solver.num_iters\n",
    "x_mid = (np.min(x1)+np.max(x1))/2\n",
    "y_mid = (np.min(y1)+np.max(y1))/2\n",
    "z_mid = fn_loss(x_mid, y_mid)\n",
    "font = {'size': 12}\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.set_xlim3d(np.min(x1), np.max(x1))\n",
    "#ax.axis('equal')\n",
    "ax.set_ylim3d(np.min(y1), np.max(y1))\n",
    "ax.scatter(x1, y1, z1, c=z1, cmap='viridis', linewidth=0.5);\n",
    "ax.set_title('Plain Vanilla Loss Path');\n",
    "ax.set_xlabel('x', labelpad=15)\n",
    "ax.set_ylabel('y', labelpad=15)\n",
    "ax.set_zlabel('Loss Function', labelpad=12.5)\n",
    "ax.text(x_mid, y_mid, z_mid, (loss_min, iterations), color='b', fontsize=15, style='italic');\n",
    "plt.tight_layout()\n",
    "fig.savefig('loss_path1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The function converges after 1,599 steps.\n",
    "- However, it does not converge at the global minimum.\n",
    "- Instead, it converges at the local minima where $(x,y)=(1.6071,0.5687)$ and $f(x,y)=2.1043$\n",
    "- This is a clear sign of the weaknesses of plain-vanilla gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.3.2 Path of the loss function for a step size of 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:07.504480Z",
     "start_time": "2019-07-12T00:20:07.490478Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solver.plain_vanilla(x_init, y_init, max_iter = 2000, eta = 0.01, tol = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:07.924479Z",
     "start_time": "2019-07-12T00:20:07.512479Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vizualize loss path\n",
    "x1 = solver.x_path\n",
    "y1 = solver.y_path\n",
    "z1 = solver.loss_path\n",
    "loss_min = np.round(solver.loss_fn_min,4)\n",
    "iterations = solver.num_iters\n",
    "x_mid = (np.min(x1)+np.max(x1))/2\n",
    "y_mid = (np.min(y1)+np.max(y1))/2\n",
    "z_mid = fn_loss(x_mid, y_mid)\n",
    "font = {'size': 12}\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.set_xlim3d(np.min(x1), np.max(x1))\n",
    "#ax.axis('equal')\n",
    "ax.set_ylim3d(np.min(y1), np.max(y1))\n",
    "ax.scatter(x1, y1, z1, c=z1, cmap='viridis', linewidth=0.5);\n",
    "ax.set_title('Plain Vanilla Loss Path');\n",
    "ax.set_xlabel('x', labelpad=15)\n",
    "ax.set_ylabel('y', labelpad=15)\n",
    "ax.set_zlabel('Loss Function', labelpad=12.5)\n",
    "ax.text(x_mid, y_mid, z_mid, (loss_min, iterations), color='b', fontsize=15, style='italic');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The function converges after 152 iterations at the global minimum of the function(the point where $f(x,y)=-1.0316$\n",
    "- This is an indication that at large step sizes(closer to the maximum), the function will converge at the global maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T10:35:13.370219Z",
     "start_time": "2019-06-21T10:35:13.366183Z"
    }
   },
   "source": [
    "#### 1.6.3.3 Minimum of loss function at maximum step size of 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:07.931509Z",
     "start_time": "2019-07-12T00:20:07.926475Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solver.plain_vanilla(x_init, y_init, max_iter = 2000, eta = 0.02, tol = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:08.349477Z",
     "start_time": "2019-07-12T00:20:07.937478Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vizualize loss path\n",
    "x1 = solver.x_path\n",
    "y1 = solver.y_path\n",
    "z1 = solver.loss_path\n",
    "loss_min = np.round(solver.loss_fn_min,4)\n",
    "iterations = solver.num_iters\n",
    "x_mid = (np.min(x1)+np.max(x1))/2\n",
    "y_mid = (np.min(y1)+np.max(y1))/2\n",
    "z_mid = fn_loss(x_mid, y_mid)\n",
    "font = {'size': 12}\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.set_xlim3d(np.min(x1), np.max(x1))\n",
    "#ax.axis('equal')\n",
    "ax.set_ylim3d(np.min(y1), np.max(y1))\n",
    "ax.scatter(x1, y1, z1, c=z1, cmap='viridis', linewidth=0.5);\n",
    "ax.set_title('Plain Vanilla Loss Path');\n",
    "ax.set_xlabel('x', labelpad=15)\n",
    "ax.set_ylabel('y', labelpad=15)\n",
    "ax.set_zlabel('Loss Function', labelpad=12.5)\n",
    "ax.text(x_mid, y_mid, z_mid, (loss_min, iterations), color='b', fontsize=15, style='italic');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the step size is increased from 0.01 to 0.02, the number of iterations needed to converge decrese from 152 to 62.\n",
    "- The function converges also at the global minimum\n",
    "- At large step sizes, we can say that the function will converge in most cases to the global minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T16:46:54.019635Z",
     "start_time": "2019-06-30T16:46:54.011613Z"
    }
   },
   "source": [
    "### 1.6.4 Experimenting with many step sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T02:44:24.889724Z",
     "start_time": "2019-07-12T02:44:24.502726Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eta = np.linspace(0.0005,0.02,num=50, endpoint=True)\n",
    "loss = []\n",
    "iterations = []\n",
    "for z in eta:\n",
    "    solver.plain_vanilla(x_init, y_init, max_iter = 2000, eta = z, tol = 1e-5)\n",
    "    loss_i = np.round(solver.loss_fn_min, 4)\n",
    "    iters = solver.num_iters\n",
    "    loss.append(loss_i)\n",
    "    iterations.append(iters)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **The plot below shows the effect of incresing the step size on the number of steps needed for the function to converge at a minimum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T02:44:27.740485Z",
     "start_time": "2019-07-12T02:44:27.420451Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Effect of step size on number of iterations needed for convergence\n",
    "font = {'size': 18}\n",
    "matplotlib.rc('font', **font)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.scatter(eta, iterations, c=iterations)\n",
    "ax1.set_xlabel('Step size')\n",
    "ax1.set_ylabel('Number of iterations')\n",
    "ax1.set_title('Effect of step size on number of iterations-PV')\n",
    "ax1.set_xticks(np.arange(0,0.02,0.005))\n",
    "plt.tight_layout()\n",
    "fig.savefig('iterations1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **The plot below shows the effect of incresing the minimum achieved by the loss function when it converges to a minimum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T02:44:30.212661Z",
     "start_time": "2019-07-12T02:44:29.910694Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Effect of step size on point of convergence\n",
    "font = {'size': 18}\n",
    "matplotlib.rc('font', **font)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.scatter(eta, loss, c=loss)\n",
    "ax1.set_xlabel('Step size')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Effect of step size on minimum achieved-PV')\n",
    "ax1.text(-0.005,1,('The scatter plot shows the minimum achieved'))\n",
    "ax1.text(-0.005,0.8,('by the loss function at each step size'))\n",
    "ax1.set_xticks(np.arange(-0.005,0.025,0.005))\n",
    "plt.tight_layout()\n",
    "fig.savefig('min_loss1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The plot below shows the distribution of the minimums achieved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T02:44:32.953118Z",
     "start_time": "2019-07-12T02:44:32.770509Z"
    }
   },
   "outputs": [],
   "source": [
    "#Distribution of the minimas achieved\n",
    "df = pd.DataFrame({'freq': loss})\n",
    "x = df.groupby('freq', as_index=False).size()\n",
    "font= {'size': 12}\n",
    "ax = x.plot(figsize=(8,8), kind='bar', title = 'Frequency Plot-PV', cmap='viridis')\n",
    "ax.set_xlabel(\"Loss Function Value\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "plt.show\n",
    "#Rotate labels on x-axis\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(0)\n",
    "# For each bar: Place a label\n",
    "def add_value_labels(ax, spacing=5):\n",
    "    for rect in ax.patches:\n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2\n",
    "        # Number of points between bar and label. Change to your liking.\n",
    "        space = spacing\n",
    "        va = 'bottom'\n",
    "        if y_value < 0:\n",
    "            space *= -1\n",
    "            va = 'top'\n",
    "        label = \"{:.1f}\".format(y_value)\n",
    "        ax.annotate(label,(x_value, y_value), xytext=(0, space),\n",
    "                    textcoords=\"offset points\",ha='center',va=va)\n",
    "add_value_labels(ax)\n",
    "plt.savefig('min_loss_freq1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:11.258324Z",
     "start_time": "2019-07-12T00:20:11.252328Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count= Counter(loss)\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Obsevations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the chart above, it can be deduced that at very small step sizes, the function will converge at the nearest local minimum which is at $(x,y)=(1.6071,0.5687)$\n",
    "- Increasing the step sizes eventually leads to the function converging at the second nearest minima which is also a global minimum at $(x,y)=(-0.0898,0.7127)$\n",
    "- A further in step size leads to the function going past the initial global minimum to another minimum which is not the global minimum at $(x,y)=(-1.7036,0.7961)$ before again settling at the second global minimum at $(x,y)=(0.0898,-0.7127)$\n",
    "- Maintaining the step size within the bounds determined(less than 0.021) ensures that the function converges over all instances.\n",
    "- It however converges at the global minimum only 50% of the time which is a highlighter of its greatest weakness.\n",
    "- Its other weakness comes about when it gets close to the a minimum. The algorithm converges slowly leading to the need for many iterations for the function to converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='MomentumGD'></a>\n",
    "## 1.7 Momentum Gradient Descent\n",
    "[Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T04:15:59.930041Z",
     "start_time": "2019-07-10T04:15:59.925042Z"
    }
   },
   "source": [
    "- Momentum gradient descent was formulated in a bid to addresses the key limitations of plain-vanilla:\n",
    "    1. Speed of convergence and \n",
    "    2. Inability to go past local minima to the global minima at small step sizes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.1 Interactive Demonstartion of Momentum Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:11.780329Z",
     "start_time": "2019-07-12T00:20:11.260324Z"
    }
   },
   "outputs": [],
   "source": [
    "interactive_momentun_gd_manual = interact_manual(solver.find_min2, x_init=FloatSlider(description='Initial x', min=-3, max=3, step=0.1,readout_format = '.1f',value = 3),\n",
    "                                                 y_init=FloatSlider(description='Initial y', min=-2, max=2, step=0.1,readout_format = '.1f',value = 2),\n",
    "                                                 max_iter=IntSlider( min=0, max=2000, step=1,value = 2000),\n",
    "                                                 eta=FloatSlider(description='Step size',min=0.001, max=0.0065, step=0.0005,readout_format = '.3f',value = 0.001),\n",
    "                                                 tol =FloatSlider(description='Tolerance',min=0, max= 0.001, step=1e-5,readout_format = '.4f',value =  1e-5),\n",
    "                                                 alpha =FloatSlider(description='Alpha',min=0, max= 0.95, step=0.05,readout_format = '.4f',value =  0.9))\n",
    "\n",
    "interactive_momentun_gd_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='MomentumGD_0.001'></a>\n",
    "### 1.7.2 Path of the loss function for a step size of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:12.359322Z",
     "start_time": "2019-07-12T00:20:11.782321Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "solver.momentum(x_init, y_init, max_iter = 2000, eta = 0.001, tol = 1e-5, alpha = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:13.013571Z",
     "start_time": "2019-07-12T00:20:12.361326Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Vizualize loss path\n",
    "x1 = solver.x_path\n",
    "y1 = solver.y_path\n",
    "z1 = solver.loss_path\n",
    "loss_min = np.round(solver.loss_fn_min,4)\n",
    "iterations = solver.num_iters\n",
    "x_mid = (np.min(x1)+np.max(x1))/2\n",
    "y_mid = (np.min(y1)+np.max(y1))/2\n",
    "z_mid = fn_loss(x_mid, y_mid)\n",
    "font = {'size': 12}\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.set_xlim3d(np.min(x1), np.max(x1))\n",
    "ax.set_ylim3d(np.min(y1), np.max(y1))\n",
    "ax.scatter(x1, y1, z1, c=z1, cmap='viridis', linewidth=0.5);\n",
    "ax.set_title('Momentum GD Loss Path');\n",
    "ax.set_xlabel('x', labelpad=15)\n",
    "ax.set_ylabel('y', labelpad=15)\n",
    "ax.set_zlabel('Loss Function', labelpad=12.5)\n",
    "ax.text(x_mid, y_mid, z_mid, (loss_min, iterations), color='b', fontsize=15, style='italic');\n",
    "plt.tight_layout()\n",
    "fig.savefig('loss_path2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES**\n",
    "\n",
    "- The function converges at $(x,y)=(-1.6071,-0.5687)$ after 238 iterations\n",
    "- This is however not a global minimum.\n",
    "- Based on the observation, we can conclude that momentum gradient descent:\n",
    "    1. Skipped the other minimas achieved under plain vanilla\n",
    "    2. Converged in fewer steps than under plain vanilla for the same step size(Refer to [Plain Vanilla at 0.001](#PlainVanillaGD_0.001))\n",
    "- While this is a good indicator that it achieves its purpose(skipping past the local minima) it also shows that the function went past the global minima\n",
    "- This is one of the weaknesses of momentum gradient descent(the steps at each iteration are not informed(the model is blind))\n",
    "- The denseness of the plot towards the minimum another weaknesses of the momentum gradient descent: if it skips a minima but doesn't go past the next maxima, the function will oscillate around the minima till it settles at the minima\n",
    "\n",
    "<br>[Go back to Nestrov's at step size 0.001](#NestrovsAGD_0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.3 Experimenting with many step sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T02:43:46.302224Z",
     "start_time": "2019-07-12T02:43:46.164256Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eta = np.linspace(0.0005,0.02,num=50, endpoint=True)\n",
    "loss = []\n",
    "iterations = []\n",
    "for z in eta:\n",
    "    solver.momentum(x_init, y_init, max_iter = 2000, eta = z, tol = 1e-5, alpha=0.9)\n",
    "    loss_i = np.round(solver.loss_fn_min, 4)\n",
    "    iters = solver.num_iters\n",
    "    loss.append(loss_i)\n",
    "    iterations.append(iters)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **The plot below shows the effect of incresing the step size on the number of steps needed for the function to converge at a minimum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T02:43:50.926614Z",
     "start_time": "2019-07-12T02:43:50.682607Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Effect of step size on number of iterations\n",
    "font = {'size': 18}\n",
    "matplotlib.rc('font', **font)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.scatter(eta, iterations, c=iterations)\n",
    "ax1.set_xlabel('Step size')\n",
    "ax1.set_ylabel('Number of iterations')\n",
    "ax1.set_title('Effect of step size on number of iterations-Mom. GD')\n",
    "ax1.text(-0.005, 100, ('At most step sizes above 0.06, the function diverges after a few iterations'), color='b', fontsize=15, style='italic');\n",
    "ax1.text(-0.005, 80, ('hence the lower plots of number of iterations'), color='b', fontsize=15, style='italic');\n",
    "\n",
    "ax1.set_xticks(np.arange(0,0.02,0.005))\n",
    "plt.tight_layout()\n",
    "fig.savefig('iterations2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **The plot below shows the effect of incresing the minimum achieved by the loss function when it converges to a minimum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T02:43:54.787841Z",
     "start_time": "2019-07-12T02:43:54.377500Z"
    }
   },
   "outputs": [],
   "source": [
    "#Effect of step size on point of convergence\n",
    "font = {'size': 18}\n",
    "matplotlib.rc('font', **font)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.scatter(eta, loss, c=loss)\n",
    "ax1.set_xlabel('Step size')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Effect of step size on minimum achieved-Mom. GD')\n",
    "ax1.text(-0.005,1,('A scatter plot of the minimum achieved'))\n",
    "ax1.text(-0.005,0.8,('by the loss function at each step size'))\n",
    "ax1.set_xticks(np.arange(-0.005,0.025,0.005))\n",
    "plt.tight_layout()\n",
    "fig.savefig('min_loss2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The plot below shows the distribution of the minimums achieved**\n",
    "    - *Ignore the last bar of infinity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T02:43:58.168072Z",
     "start_time": "2019-07-12T02:43:57.973113Z"
    }
   },
   "outputs": [],
   "source": [
    "#Distribution of the minimas achieved\n",
    "df = pd.DataFrame({'freq': loss})\n",
    "x = df.groupby('freq', as_index=False).size()\n",
    "font= {'size': 12}\n",
    "ax = x.plot(figsize=(8,8), kind='bar', title = 'Frequency Plot-PV', cmap='viridis')\n",
    "ax.set_xlabel(\"Loss Function Value\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "plt.show\n",
    "#Rotate labels on x-axis\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(0)\n",
    "# For each bar: Place a label\n",
    "def add_value_labels(ax, spacing=5):\n",
    "    for rect in ax.patches:\n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2\n",
    "        # Number of points between bar and label. Change to your liking.\n",
    "        space = spacing\n",
    "        va = 'bottom'\n",
    "        if y_value < 0:\n",
    "            space *= -1\n",
    "            va = 'top'\n",
    "        label = \"{:.1f}\".format(y_value)\n",
    "        ax.annotate(label,(x_value, y_value), xytext=(0, space),\n",
    "                    textcoords=\"offset points\",ha='center',va=va)\n",
    "add_value_labels(ax)\n",
    "plt.savefig('min_loss_freq2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Obsevations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T05:09:02.084628Z",
     "start_time": "2019-07-10T05:09:02.076627Z"
    }
   },
   "source": [
    "- Of the 16 times that the function converges, it performs exceedingly better than plain-vanilla since it converges at the global minima 81% of the time\n",
    "- What is of concern however, is the fact that the function does not converge around 70% of the time.\n",
    "- This is the greatest weakness since it shows that momentum gradient descent is not forward looking, i.e:\n",
    "    - The step size does not reduce when it approaches a minimum and this is because its gradient is calculated from its current position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T15:48:01.771688Z",
     "start_time": "2019-06-30T15:48:01.763275Z"
    },
    "code_folding": []
   },
   "source": [
    "<a id='NestAccGD'></a>\n",
    "## 1.8 Nestrov's Accelerated Gradient Descent\n",
    "[Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Nestrov's Accelerated gradient descent was formulated to address the weaknesses of momentum, i.e: its inability to reduce momentum when it approaches a minimum causing it to either:\n",
    "    1. Diverging many times by going beyond the recommended bounded region\n",
    "    2. Do oscillations around a minimum before converging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8.1 Interactive Demonstartion of Nestrov's Accelerated Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:15.708998Z",
     "start_time": "2019-07-12T00:20:15.660994Z"
    }
   },
   "outputs": [],
   "source": [
    "interactive_nestrovs_gd_manual = interact_manual(solver.find_min3, x_init=FloatSlider(description='Initial x', min=-3, max=3, step=0.1,readout_format = '.1f',value = 3),\n",
    "                                                      y_init=FloatSlider(description='Initial y', min=-2, max=2, step=0.1,readout_format = '.1f',value = 2),\n",
    "                                                      max_iter=IntSlider( min=0, max=2000, step=1,value = 2000),\n",
    "                                                      eta=FloatSlider(description='Step size',min=0.001, max=0.0065, step=0.0005,readout_format = '.3f',value = 0.001),\n",
    "                                                      tol =FloatSlider(description='Tolerance',min=0, max= 0.001, step=1e-5,readout_format = '.4f',value =  1e-5),\n",
    "                                                      alpha =FloatSlider(description='Alpha',min=0, max= 0.95, step=0.05,readout_format = '.4f',value =  0.9))\n",
    "\n",
    "interactive_nestrovs_gd_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T04:42:43.869449Z",
     "start_time": "2019-07-10T04:42:43.865447Z"
    }
   },
   "source": [
    "### 1.8.2 Path of the loss function for a step size of 0.001\n",
    "<a id='NestrovsAGD_0.001'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:15.944370Z",
     "start_time": "2019-07-12T00:20:15.709999Z"
    }
   },
   "outputs": [],
   "source": [
    "solver.nag(x_init, y_init, max_iter = 2000, eta = 0.001, tol = 1e-5, alpha = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:20:16.496371Z",
     "start_time": "2019-07-12T00:20:15.946333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vizualize loss path\n",
    "x1 = solver.x_path\n",
    "y1 = solver.y_path\n",
    "z1 = solver.loss_path\n",
    "loss_min = np.round(solver.loss_fn_min,4)\n",
    "iterations = solver.num_iters\n",
    "x_mid = (np.min(x1)+np.max(x1))/2\n",
    "y_mid = (np.min(y1)+np.max(y1))/2\n",
    "z_mid = fn_loss(x_mid, y_mid)\n",
    "font = {'size': 12}\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.set_xlim3d(np.min(x1), np.max(x1))\n",
    "#ax.axis('equal')\n",
    "ax.set_ylim3d(np.min(y1), np.max(y1))\n",
    "ax.scatter(x1, y1, z1, c=z1, cmap='viridis', linewidth=0.5);\n",
    "ax.set_title(\"Nestrov's Accelerated GD Loss Path\");\n",
    "ax.set_xlabel('x', labelpad=15)\n",
    "ax.set_ylabel('y', labelpad=15)\n",
    "ax.set_zlabel('Loss Function', labelpad=12.5)\n",
    "ax.text(x_mid, y_mid, z_mid, (loss_min, iterations), color='b', fontsize=15, style='italic');\n",
    "plt.tight_layout()\n",
    "fig.savefig('loss_path3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES**\n",
    "\n",
    "- The function converges at $(x,y)=(0.0898,-0.7127)$ after 201 iterations at a global minimum.\n",
    "- The function converged in fewer steps than under plain vanilla(1,599 steps) and momentum gradient descent(238 steps) for the same step size and bettered them further by converging at a global minimum(Refer to [Plain Vanilla at 0.001](#PlainVanillaGD_0.001) and [Momentum Gradient Descent at 0.001](#MomentumGD_0.001) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8.3 Experimenting with many step sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T02:39:40.526178Z",
     "start_time": "2019-07-12T02:39:40.435183Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eta = np.linspace(0.0005,0.02,num=50, endpoint=True)\n",
    "loss = []\n",
    "iterations = []\n",
    "for z in eta:\n",
    "    solver.nag(x_init, y_init, max_iter = 2000, eta = z, tol = 1e-5, alpha=0.9)\n",
    "    loss_i = np.round(solver.loss_fn_min, 4)\n",
    "    iters = solver.num_iters\n",
    "    loss.append(loss_i)\n",
    "    iterations.append(iters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **The plot below shows the effect of incresing the step size on the number of steps needed for the function to converge at a minimum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T02:43:14.781404Z",
     "start_time": "2019-07-12T02:43:13.948352Z"
    }
   },
   "outputs": [],
   "source": [
    "#Effect of step size on number of iterations\n",
    "font = {'size': 18}\n",
    "matplotlib.rc('font', **font)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.scatter(eta, iterations, c=iterations)\n",
    "ax1.set_xlabel('Step size')\n",
    "ax1.set_ylabel('Number of iterations')\n",
    "ax1.set_title('Effect of step size on number of iterations-NAG')\n",
    "ax1.text(-0.005, 100, ('At most step sizes above 0.09, the function diverges after a few iterations'), color='b', fontsize=15, style='italic');\n",
    "ax1.text(-0.005, 80, ('hence the lower plots of number of iterations'), color='b', fontsize=15, style='italic');\n",
    "\n",
    "ax1.set_xticks(np.arange(0,0.02,0.005))\n",
    "plt.tight_layout()\n",
    "fig.savefig('iterations3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **The plot below shows the effect of incresing the minimum achieved by the loss function when it converges to a minimum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T02:43:21.261275Z",
     "start_time": "2019-07-12T02:43:20.828236Z"
    }
   },
   "outputs": [],
   "source": [
    "#Effect of step size on point of convergence\n",
    "font = {'size': 18}\n",
    "matplotlib.rc('font', **font)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.scatter(eta, loss, c=loss)\n",
    "ax1.set_xlabel('Step size')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Effect of step size on minimum achieved-NAG')\n",
    "ax1.text(-0.005,1,('A scatter plot of the minimum achieved'))\n",
    "ax1.text(-0.005,0.8,('by the loss function at each step size'))\n",
    "ax1.set_xticks(np.arange(-0.005,0.025,0.005))\n",
    "plt.tight_layout()\n",
    "fig.savefig('min_loss3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The plot below shows the distribution of the minimums achieved**\n",
    "    - *Ignore the last bar of infinity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T02:43:33.638203Z",
     "start_time": "2019-07-12T02:43:33.336245Z"
    }
   },
   "outputs": [],
   "source": [
    "#Distribution of the minimas achieved\n",
    "df = pd.DataFrame({'freq': loss})\n",
    "x = df.groupby('freq', as_index=False).size()\n",
    "font= {'size': 12}\n",
    "ax = x.plot(figsize=(8,8), kind='bar', title = 'Frequency Plot-PV', cmap='viridis')\n",
    "ax.set_xlabel(\"Loss Function Value\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "#Rotate labels on x-axis\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(0)\n",
    "# For each bar: Place a label\n",
    "def add_value_labels(ax, spacing=5):\n",
    "    for rect in ax.patches:\n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2\n",
    "        # Number of points between bar and label. Change to your liking.\n",
    "        space = spacing\n",
    "        va = 'bottom'\n",
    "        if y_value < 0:\n",
    "            space *= -1\n",
    "            va = 'top'\n",
    "        label = \"{:.1f}\".format(y_value)\n",
    "        ax.annotate(label,(x_value, y_value), xytext=(0, space),\n",
    "                    textcoords=\"offset points\",ha='center',va=va)\n",
    "add_value_labels(ax)\n",
    "plt.savefig('min_loss_freq3.png')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Obsevations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The algorithm converged in more cases than momentum gradient descent( 46% of the time compared to 34% under momentum)\n",
    "- This highlights the ability of Nestrov's Accelerated gradient descent to reduce the size of step in advance as it approaches a minimum hence the higher number of convergences.\n",
    "- However, it also brings about one weakness: the function converges at a minimum other than the global minimum at more instances \n",
    "    -Of the times it converges, Nestrov's Accelerated gradient descent converges at the global minimum 56% of the time compared to 80% under momentum gradient design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## 1.9 Conclusion\n",
    "[Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the above plots, we can note that despite it's inefficincies, plain vanilla will converge in most cases provided that the maximum step size is not breached\n",
    "- If you compare the point at which it converges, plain vanilla performs worst since it converges at a local minimum 505 of the time.\n",
    "- Momentum gradient descent improves considerably on plain vanilla gradient descent by:\n",
    "        - Reducing the number of steps taken to convergence and\n",
    "        - Increasing the proportion at which it converges to the global minimum(81% of the tme)\n",
    "    - However, the function converges only 30% of the time which is a weakness brought about by accelerating without considering the future position\n",
    "- Nestrov's Accelerated gradient descent improves on Momentum gradient descent by:\n",
    "        - Reducing the number of steps taken to convergence further\n",
    "        - Increasing the proportion at which it converges to a minimum(56% of the tme compared to 30% under momentum)\n",
    "    - Despite the increase in number of times the function converges, the number of times it converged at the global mnimum did not change from the number under momentum.\n",
    "    - The extra times it converged, it converged at another local minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "100px",
    "left": "112px",
    "top": "111.14px",
    "width": "273.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
